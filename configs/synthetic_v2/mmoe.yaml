model:
  type: 'mt'
  name: 'mmoe'
  num_experts: 8
  expert_hidden_dims: [256, 128]
  tower_hidden_dims: [64]
  embed_dim: 16
training:
  epochs: 10
  lr: 0.001
  optimizer: 'adamw'
  weight_decay: 0.0000
  batch_size: 2048
  dropout: 0.0